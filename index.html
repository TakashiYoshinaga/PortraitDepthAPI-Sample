<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Require the peer dependencies of depth-estimation. -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <!-- You must explicitly require a TF.js backend if you're not using the TF.js union bundle. -->
  <!-- WebGL is the recommended backend. -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-segmentation"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation"></script>

  <!--今回のハンズオンで行う処理を記述-->
  <script type="text/javascript">
     let canvasElement;
    let canvasCtx;
    var estimator;
    var videoElement;
    var estimationConfig;
    //初期化
    window.onload = async function() {
      //ビデオ要素の取得
      videoElement = document.getElementById('input_video');
      //表示用のCanvasを取得
      canvasElement = document.getElementById('output_canvas');
      //Canvas描画に関する情報にアクセス
      canvasCtx = canvasElement.getContext('2d');
           
      const constraints = {
        video: {
          width: {
            ideal: 320,
          },
          height: {
            ideal: 240,
          },
        }
      };
      
      await navigator.mediaDevices.getUserMedia(constraints).then(stream => {
        videoElement.srcObject = stream;
        videoElement.play()
      }).catch(e => {
        console.log(e)
      })
      
      const model = depthEstimation.SupportedModels.ARPortraitDepth;
      estimator = await depthEstimation.createEstimator(model);
      estimationConfig = {
        minDepth: 0, // The minimum depth value outputted by the estimator.
        maxDepth: 1, // The maximum depth value outputted by the estimator.
      };

      loop();
    };
    
    async function loop(){
      let width=videoElement.videoWidth;
      let height=videoElement.videoHeight;//results.image.height;
      //画像のサイズとcanvasのサイズが異なる場合はサイズを調整
      if(width!=canvasElement.width){
        //入力画像と同じサイズのcanvas(描画領域)を用意
        canvasElement.width=width;
        canvasElement.height=height;
      }
      var depthMap = await estimator.estimateDepth(videoElement, estimationConfig);
      var depthCanvas=await depthMap.toCanvasImageSource();
      var depthCtx=depthCanvas.getContext('2d');
      var imageData = depthCtx.getImageData(0, 0, width, height);
      canvasCtx .putImageData(imageData, 0, 0);
         
      setTimeout(loop,30);
    }
  
  </script>
</head>

<body>
  <div style="display:flex;">
    <video id="input_video" ></video>
    <canvas id="output_canvas"></canvas>
  </div>
 </body>
</html>



